{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "\n",
    "credData.loc[credData[15] == '+', 15] = 1\n",
    "credData.loc[credData[15] == '-', 15] = 0\n",
    "credData.sample(5)\n",
    "\n",
    "credData.replace('?', np.nan, inplace=True)\n",
    "newCred = credData.dropna(axis=0)\n",
    "\n",
    "X = newCred.loc[:, 0:14]\n",
    "y = newCred.loc[:, 15]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "catTrans = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrans = Pipeline(steps=[('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      object\n",
       "1     float64\n",
       "2     float64\n",
       "3      object\n",
       "4      object\n",
       "5      object\n",
       "6      object\n",
       "7     float64\n",
       "8      object\n",
       "9      object\n",
       "10      int64\n",
       "11     object\n",
       "12     object\n",
       "13    float64\n",
       "14      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 2, 7, 10, 13, 14], dtype='int64')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numFeatures = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 3, 4, 5, 6, 8, 9, 11, 12], dtype='int64')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catFeatures = X.select_dtypes(include=['object']).columns\n",
    "catFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numTrans, numFeatures),\n",
    "    ('categoric', catTrans, catFeatures)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105658</td>\n",
       "      <td>-0.444900</td>\n",
       "      <td>1.377002</td>\n",
       "      <td>-0.553206</td>\n",
       "      <td>0.570065</td>\n",
       "      <td>-0.174241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.084238</td>\n",
       "      <td>1.115032</td>\n",
       "      <td>-0.528306</td>\n",
       "      <td>-0.553206</td>\n",
       "      <td>-0.602470</td>\n",
       "      <td>-0.167337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.416675</td>\n",
       "      <td>-0.080916</td>\n",
       "      <td>0.592889</td>\n",
       "      <td>-0.327276</td>\n",
       "      <td>-0.367963</td>\n",
       "      <td>-0.174241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.795428</td>\n",
       "      <td>1.418699</td>\n",
       "      <td>-0.189778</td>\n",
       "      <td>-0.553206</td>\n",
       "      <td>-0.485217</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.125497</td>\n",
       "      <td>0.439061</td>\n",
       "      <td>-0.636809</td>\n",
       "      <td>-0.553206</td>\n",
       "      <td>-0.250710</td>\n",
       "      <td>-0.174241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5    6    7    8   \\\n",
       "0  0.105658 -0.444900  1.377002 -0.553206  0.570065 -0.174241  0.0  1.0  0.0   \n",
       "1 -1.084238  1.115032 -0.528306 -0.553206 -0.602470 -0.167337  1.0  0.0  0.0   \n",
       "2 -0.416675 -0.080916  0.592889 -0.327276 -0.367963 -0.174241  0.0  1.0  0.0   \n",
       "3 -0.795428  1.418699 -0.189778 -0.553206 -0.485217  0.024974  0.0  1.0  0.0   \n",
       "4 -1.125497  0.439061 -0.636809 -0.553206 -0.250710 -0.174241  0.0  1.0  0.0   \n",
       "\n",
       "    9   ...   36   37   38   39   40   41   42   43   44   45  \n",
       "0  0.0  ...  0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  \n",
       "1  1.0  ...  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "2  1.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  \n",
       "3  1.0  ...  0.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  \n",
       "4  0.0  ...  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tran_train = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
    "X_tran_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.059376</td>\n",
       "      <td>-0.531217</td>\n",
       "      <td>-0.623789</td>\n",
       "      <td>-0.553206</td>\n",
       "      <td>0.687319</td>\n",
       "      <td>-0.174241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.063609</td>\n",
       "      <td>-0.878562</td>\n",
       "      <td>-0.600642</td>\n",
       "      <td>-0.327276</td>\n",
       "      <td>0.101051</td>\n",
       "      <td>-0.174076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.648620</td>\n",
       "      <td>1.929316</td>\n",
       "      <td>1.847181</td>\n",
       "      <td>0.802371</td>\n",
       "      <td>-0.661097</td>\n",
       "      <td>-0.174241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.203242</td>\n",
       "      <td>3.402933</td>\n",
       "      <td>2.245025</td>\n",
       "      <td>2.383877</td>\n",
       "      <td>-1.071485</td>\n",
       "      <td>0.927028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.451332</td>\n",
       "      <td>-0.644572</td>\n",
       "      <td>-0.612215</td>\n",
       "      <td>-0.553206</td>\n",
       "      <td>-0.485217</td>\n",
       "      <td>-0.174241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5    6    7    8   \\\n",
       "0 -0.059376 -0.531217 -0.623789 -0.553206  0.687319 -0.174241  0.0  1.0  0.0   \n",
       "1 -1.063609 -0.878562 -0.600642 -0.327276  0.101051 -0.174076  0.0  1.0  0.0   \n",
       "2  0.648620  1.929316  1.847181  0.802371 -0.661097 -0.174241  0.0  1.0  0.0   \n",
       "3  2.203242  3.402933  2.245025  2.383877 -1.071485  0.927028  1.0  0.0  0.0   \n",
       "4 -0.451332 -0.644572 -0.612215 -0.553206 -0.485217 -0.174241  0.0  1.0  0.0   \n",
       "\n",
       "    9   ...   36   37   38   39   40   41   42   43   44   45  \n",
       "0  1.0  ...  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "1  0.0  ...  0.0  1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  \n",
       "2  1.0  ...  0.0  0.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  \n",
       "3  1.0  ...  0.0  0.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  \n",
       "4  1.0  ...  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tran_test = pd.DataFrame(preprocessor.transform(X_test))\n",
    "X_tran_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Dimensionality Reduction to the Feature Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "\n",
    "credData.loc[credData[15] == '+', 15] = 1\n",
    "credData.loc[credData[15] == '-', 15] = 0\n",
    "credData.sample(5)\n",
    "\n",
    "credData.replace('?', np.nan, inplace=True)\n",
    "newCred = credData.dropna(axis=0)\n",
    "\n",
    "X = newCred.loc[:, 0:14]\n",
    "y = newCred.loc[:, 15]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "catTrans = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "numTrans = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "numFeatures = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "catFeatures = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numTrans, numFeatures),\n",
    "    ('categoric', catTrans, catFeatures)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir o dataset para 10 dimensões\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor), ('dimred', PCA(10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 10)\n",
      "(196, 10)\n"
     ]
    }
   ],
   "source": [
    "X_tran_train = pd.DataFrame(estimator.fit_transform(X_train))\n",
    "X_tran_test = pd.DataFrame(estimator.transform(X_test))\n",
    "\n",
    "print(X_tran_train.shape)\n",
    "print(X_tran_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Predictions Using ML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "\n",
    "credData.loc[credData[15] == '+', 15] = 1\n",
    "credData.loc[credData[15] == '-', 15] = 0\n",
    "credData.sample(5)\n",
    "\n",
    "credData.replace('?', np.nan, inplace=True)\n",
    "newCred = credData.dropna(axis=0)\n",
    "\n",
    "X = newCred.loc[:, 0:14]\n",
    "y = newCred.loc[:, 15].astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "catTrans = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "numTrans = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "numFeatures = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "catFeatures = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numTrans, numFeatures),\n",
    "    ('categoric', catTrans, catFeatures)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('dimred', PCA(10)),\n",
    "    ('clf', LogisticRegression(random_state=123))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  with_std=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  Int64Index([1, 2, 7, 10, 13, 14], dtype='int64')),\n",
       "                                                 ('categoric',\n",
       "                                                  Pipeline(memory=None,...\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=10,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=123,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877551020408163"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 11]\n",
      " [11 78]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       107\n",
      "           1       0.88      0.88      0.88        89\n",
      "\n",
      "    accuracy                           0.89       196\n",
      "   macro avg       0.89      0.89      0.89       196\n",
      "weighted avg       0.89      0.89      0.89       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot-Checking Models Using ML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "\n",
    "credData.loc[credData[15] == '+', 15] = 1\n",
    "credData.loc[credData[15] == '-', 15] = 0\n",
    "credData.sample(5)\n",
    "\n",
    "credData.replace('?', np.nan, inplace=True)\n",
    "newCred = credData.dropna(axis=0)\n",
    "\n",
    "X = newCred.loc[:, 0:14]\n",
    "y = newCred.loc[:, 15].astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "catTrans = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "numTrans = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "numFeatures = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "catFeatures = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numTrans, numFeatures),\n",
    "    ('categoric', catTrans, catFeatures)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    RandomForestClassifier(random_state=123),\n",
    "    AdaBoostClassifier(random_state=123),\n",
    "    LogisticRegression(random_state=123)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Model score: 0.83\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=123,\n",
      "                       verbose=0, warm_start=False)\n",
      "Model score: 0.86\n",
      "\n",
      "\n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=123)\n",
      "Model score: 0.86\n",
      "\n",
      "\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Model score: 0.89\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    estimator = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('dimred', PCA(10)),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    print(classifier)\n",
    "    print('Model score: %.2f\\n\\n\\n' %estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search and Cross-Validation with ML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter15/Dataset/crx.data'\n",
    "credData = pd.read_csv(filename,sep=\",\",header = None,na_values = \"?\")\n",
    "\n",
    "credData.loc[credData[15] == '+', 15] = 1\n",
    "credData.loc[credData[15] == '-', 15] = 0\n",
    "credData.sample(5)\n",
    "\n",
    "credData.replace('?', np.nan, inplace=True)\n",
    "newCred = credData.dropna(axis=0)\n",
    "\n",
    "X = newCred.loc[:, 0:14]\n",
    "y = newCred.loc[:, 15].astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "catTrans = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "numTrans = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "numFeatures = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "catFeatures = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numTrans, numFeatures),\n",
    "    ('categoric', catTrans, catFeatures)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('dimred', PCA(10)),\n",
    "    ('classifier', AdaBoostClassifier(random_state=123))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __ (double underscore) faz a associação entre os parâmetros\n",
    "param_grid = {'dimred__n_components': [10, 12, 15],\n",
    "             'classifier__n_estimators': [50, 100, 200],\n",
    "             'classifier__learning_rate': [0.7, 0.6, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('numeric',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('scaler',\n",
       "                                                                                          StandardScaler(copy=True,\n",
       "                                                                                                         with_mean=True,\n",
       "                                                                                                         with_std=True))],\n",
       "                                                                                  verbose=False),\n",
       "                                                                         Int64Index([1, 2, 7, 10, 13, 14], dtype...\n",
       "                                        AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                           base_estimator=None,\n",
       "                                                           learning_rate=1.0,\n",
       "                                                           n_estimators=50,\n",
       "                                                           random_state=123))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'classifier__learning_rate': [0.7, 0.6, 1.0],\n",
       "                         'classifier__n_estimators': [50, 100, 200],\n",
       "                         'dimred__n_components': [10, 12, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.7,\n",
       " 'classifier__n_estimators': 50,\n",
       " 'dimred__n_components': 15}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 17]\n",
      " [14 75]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       107\n",
      "           1       0.82      0.84      0.83        89\n",
      "\n",
      "    accuracy                           0.84       196\n",
      "   macro avg       0.84      0.84      0.84       196\n",
      "weighted avg       0.84      0.84      0.84       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
